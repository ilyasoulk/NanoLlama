d_model : 2048
vocab_size : 128256
num_layers : 16
d_head : 64
q_heads : 32
kv_heads : 8
rms_norm_eps : 0.00001
rope_theta : 500000.0
seq_len : 10
causal: False
batch_size: 1
do_flash: False

